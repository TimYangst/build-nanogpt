{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "821f6af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch softmax example\n",
      "tensor([[-0.2735,  0.3391,  0.2336, -0.2055,  0.0382,  1.0012],\n",
      "        [-0.0193,  0.2482,  0.1785, -0.7953,  0.5555,  0.8238]])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "print('torch softmax example')\n",
    "A = torch.randn(2, 6)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e0ca531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0951, 0.1754, 0.1579, 0.1017, 0.1298, 0.3401],\n",
      "        [0.1237, 0.1616, 0.1507, 0.0569, 0.2197, 0.2874]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "A_exp = torch.exp(A)\n",
    "A_sum = torch.sum(A_exp, dim=1).unsqueeze(1)\n",
    "P = A_exp / A_sum\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "069a02ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0951, 0.1754, 0.1579, 0.1017, 0.1298, 0.3401],\n",
      "        [0.1237, 0.1616, 0.1507, 0.0569, 0.2197, 0.2874]])\n"
     ]
    }
   ],
   "source": [
    "# safe softmax implementation\n",
    "A_max, _ = torch.max(A, dim=1, keepdim=True)\n",
    "A_exp = torch.exp(A - A_max)\n",
    "A_sum = torch.sum(A_exp, dim=1, keepdim=True)\n",
    "P = A_exp / A_sum\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d4b096",
   "metadata": {},
   "source": [
    "# Online Softmax (3-pass vs 2-pass)\n",
    "\n",
    "Below are Markdown versions of the algorithms in the image and PyTorch implementations.\n",
    "\n",
    "## Algorithm: 3‑pass Online Softmax\n",
    "\n",
    "**Idea:** Compute the global max in pass 1, the normalized sum of exponentials in pass 2, and the probabilities in pass 3.\n",
    "\n",
    "Let the input vector be \\(x_1, x_2, \\dots, x_N\\).\n",
    "\n",
    "```\n",
    "m_0 = -inf\n",
    "d_0 = 0.0\n",
    "for i = 1..N:\n",
    "    m_i = max(m_{i-1}, x_i)         # pass 1: running max -> m_N is global max\n",
    "\n",
    "for i = 1..N:\n",
    "    d_i = d_{i-1} + exp(x_i - m_N)  # pass 2: sum of shifted exponentials -> d_N\n",
    "\n",
    "for i = 1..N:\n",
    "    a_i = exp(x_i - m_N) / d_N      # pass 3: probabilities\n",
    "```\n",
    "\n",
    "This is equivalent to the standard numerically-stable softmax that subtracts the global max.\n",
    "\n",
    "## Algorithm: 2‑pass Online Softmax\n",
    "\n",
    "**Idea:** Maintain a *running* max and a *rescaled* running sum in a single forward pass, then compute probabilities in pass 2.\n",
    "\n",
    "```\n",
    "m_0   = -inf\n",
    "d'_0  = 0.0\n",
    "for i = 1..N:\n",
    "    m_i   = max(m_{i-1}, x_i)                         # update running max\n",
    "    d'_i  = d'_{i-1} * exp(m_{i-1} - m_i) + exp(x_i - m_i)\n",
    "\n",
    "for i = 1..N:\n",
    "    a_i = exp(x_i - m_N) / d'_N\n",
    "```\n",
    "\n",
    "The factor `exp(m_{i-1} - m_i)` keeps the accumulated sum in the same scale after the max increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "272e2890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0951, 0.1754, 0.1579, 0.1017, 0.1298, 0.3401],\n",
      "        [0.1237, 0.1616, 0.1507, 0.0569, 0.2197, 0.2874]])\n"
     ]
    }
   ],
   "source": [
    "def online_softmax_3pass_vec(x: torch.Tensor) -> torch.Tensor:\n",
    "    assert x.dim() == 1\n",
    "    m = torch.tensor(-float(\"inf\"), device=x.device, dtype=x.dtype)\n",
    "    # pass 1: 全局最大\n",
    "    for i in range(x.numel()):\n",
    "        m = torch.maximum(m, x[i])\n",
    "    # pass 2: 累加 exp(x - max)\n",
    "    d = torch.tensor(0.0, device=x.device, dtype=x.dtype)\n",
    "    for i in range(x.numel()):\n",
    "        d = d + torch.exp(x[i] - m)\n",
    "    # pass 3: 概率\n",
    "    out = torch.empty_like(x)\n",
    "    for i in range(x.numel()):\n",
    "        out[i] = torch.exp(x[i] - m) / d\n",
    "    return out\n",
    "\n",
    "P=[]\n",
    "for i in range(A.shape[0]):\n",
    "    X = A[i]\n",
    "    P_online = online_softmax_3pass_vec(X)\n",
    "    P.append(P_online)\n",
    "\n",
    "P = torch.stack(P)\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "349af890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0951, 0.1754, 0.1579, 0.1017, 0.1298, 0.3401],\n",
      "        [0.1237, 0.1616, 0.1507, 0.0569, 0.2197, 0.2874]])\n"
     ]
    }
   ],
   "source": [
    "def online_softmax_2pass_vec(x: torch.Tensor) -> torch.Tensor:\n",
    "    assert x.dim() == 1\n",
    "    m = torch.tensor(-float(\"inf\"), device=x.device, dtype=x.dtype)\n",
    "    d = torch.tensor(0.0, device=x.device, dtype=x.dtype)\n",
    "    # 单次前向：维护 running max 与重标定的 running sum\n",
    "    for i in range(x.numel()):\n",
    "        xi = x[i]\n",
    "        m_new = torch.maximum(m, xi)\n",
    "        d = d * torch.exp(m - m_new) + torch.exp(xi - m_new)\n",
    "        m = m_new\n",
    "    # 第二遍：用最终 m_N 和 d_N 出概率\n",
    "    return torch.exp(x - m) / d\n",
    "\n",
    "P=[]\n",
    "for i in range(A.shape[0]):\n",
    "    X = A[i]\n",
    "    P_online = online_softmax_2pass_vec(X)\n",
    "    P.append(P_online)\n",
    "\n",
    "P = torch.stack(P)\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e346f312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0951, 0.1754, 0.1579, 0.1017, 0.1298, 0.3401],\n",
      "        [0.1237, 0.1616, 0.1507, 0.0569, 0.2197, 0.2874]])\n",
      "tensor([[0.0951, 0.1754, 0.1579, 0.1017, 0.1298, 0.3401],\n",
      "        [0.1237, 0.1616, 0.1507, 0.0569, 0.2197, 0.2874]])\n"
     ]
    }
   ],
   "source": [
    "def online_softmax_3pass(x: torch.Tensor, dim: int = -1) -> torch.Tensor:\n",
    "    x = x.transpose(dim, -1).contiguous()\n",
    "    *prefix, N = x.shape\n",
    "    y = torch.empty_like(x)\n",
    "\n",
    "    m = torch.full(prefix, -float(\"inf\"), device=x.device, dtype=x.dtype)\n",
    "    for i in range(N):\n",
    "        m = torch.maximum(m, x[..., i])\n",
    "\n",
    "    d = torch.zeros(prefix, device=x.device, dtype=x.dtype)\n",
    "    for i in range(N):\n",
    "        d = d + torch.exp(x[..., i] - m)\n",
    "\n",
    "    for i in range(N):\n",
    "        y[..., i] = torch.exp(x[..., i] - m) / d\n",
    "    return y.transpose(-1, dim)\n",
    "\n",
    "def online_softmax_2pass(x: torch.Tensor, dim: int = -1) -> torch.Tensor:\n",
    "    x = x.transpose(dim, -1).contiguous()\n",
    "    *prefix, N = x.shape\n",
    "\n",
    "    m = torch.full(prefix, -float(\"inf\"), device=x.device, dtype=x.dtype)\n",
    "    d = torch.zeros(prefix, device=x.device, dtype=x.dtype)\n",
    "    for i in range(N):\n",
    "        xi = x[..., i]\n",
    "        m_new = torch.maximum(m, xi)\n",
    "        d = d * torch.exp(m - m_new) + torch.exp(xi - m_new)\n",
    "        m = m_new\n",
    "\n",
    "    y = torch.exp(x - m.unsqueeze(-1)) / d.unsqueeze(-1)\n",
    "    return y.transpose(-1, dim)\n",
    "\n",
    "p1 = online_softmax_3pass(A, dim=1)\n",
    "p2 = online_softmax_2pass(A, dim=1)\n",
    "\n",
    "print(p1)\n",
    "print(p2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "build-nanogpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
